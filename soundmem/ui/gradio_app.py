"""
Gradioç”¨æˆ·ç•Œé¢
"""

import gradio as gr
import threading
import queue
import time
from datetime import datetime
from typing import Optional
import numpy as np

from soundmem.core import AudioRecorder, ASREngine, TextProcessor, VectorStore, RAGEngine
from soundmem.utils import load_config, ensure_directories, log

class SoundMemApp:
    """SoundMemåº”ç”¨ä¸»ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–åº”ç”¨"""
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        ensure_directories()
        
        # åŠ è½½é…ç½®
        self.config = load_config()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.recorder = AudioRecorder(
            sample_rate=self.config.sample_rate,
            channels=self.config.channels,
            chunk_duration=self.config.chunk_duration
        )
        
        self.asr_engine = ASREngine()
        self.text_processor = TextProcessor()
        self.vector_store = VectorStore(
            db_path=self.config.vector_db_path,
            collection_name=self.config.collection_name
        )
        
        self.rag_engine: Optional[RAGEngine] = None
        
        # çŠ¶æ€å˜é‡
        self.is_recording = False
        self.transcription_text = ""
        self.processing_thread: Optional[threading.Thread] = None
        self.stop_processing = False
        
        log.info("SoundMemåº”ç”¨åˆå§‹åŒ–å®Œæˆ")
    
    def initialize_models(self, progress=gr.Progress()):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            progress(0, desc="æ­£åœ¨åŠ è½½ASRæ¨¡å‹...")
            self.asr_engine.load_model()
            
            progress(0.5, desc="æ­£åœ¨åŠ è½½å‘é‡æ¨¡å‹...")
            self.vector_store.load_model()
            self.vector_store.initialize()
            
            progress(1.0, desc="æ¨¡å‹åŠ è½½å®Œæˆï¼")
            
            return "âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼å¯ä»¥å¼€å§‹ä½¿ç”¨äº†ã€‚"
        except Exception as e:
            log.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
    
    def start_recording(self):
        """å¼€å§‹å½•éŸ³"""
        if self.is_recording:
            return "âš ï¸ å½•éŸ³å·²åœ¨è¿›è¡Œä¸­", self.transcription_text
        
        try:
            # å¯åŠ¨å½•éŸ³
            self.recorder.start_recording()
            self.is_recording = True
            self.stop_processing = False
            self.transcription_text = ""
            
            # å¯åŠ¨å¤„ç†çº¿ç¨‹
            self.processing_thread = threading.Thread(target=self._process_audio_loop)
            self.processing_thread.start()
            
            log.info("å½•éŸ³å¼€å§‹")
            return "ğŸ™ï¸ å½•éŸ³ä¸­...", ""
            
        except Exception as e:
            log.error(f"å¯åŠ¨å½•éŸ³å¤±è´¥: {e}")
            return f"âŒ å¯åŠ¨å½•éŸ³å¤±è´¥: {str(e)}", ""
    
    def stop_recording(self):
        """åœæ­¢å½•éŸ³"""
        if not self.is_recording:
            return "âš ï¸ å½•éŸ³æœªåœ¨è¿›è¡Œä¸­", self.transcription_text
        
        try:
            # åœæ­¢å½•éŸ³
            self.is_recording = False
            self.stop_processing = True
            self.recorder.stop_recording()
            
            # ç­‰å¾…å¤„ç†çº¿ç¨‹ç»“æŸ
            if self.processing_thread:
                self.processing_thread.join(timeout=5)
            
            log.info("å½•éŸ³åœæ­¢")
            return "â¹ï¸ å½•éŸ³å·²åœæ­¢", self.transcription_text
            
        except Exception as e:
            log.error(f"åœæ­¢å½•éŸ³å¤±è´¥: {e}")
            return f"âŒ åœæ­¢å½•éŸ³å¤±è´¥: {str(e)}", self.transcription_text
    
    def _process_audio_loop(self):
        """éŸ³é¢‘å¤„ç†å¾ªç¯ï¼ˆåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œï¼‰
        
        åŒå±‚æ£€æµ‹æœºåˆ¶ï¼š
        1. ç®€å•èƒ½é‡æ£€æµ‹ï¼šå†³å®šä½•æ—¶å‘é€ç»™ASRï¼ˆç²—è¿‡æ»¤ï¼‰
        2. FunASRçš„VADï¼šç²¾ç¡®åˆ†æ®µå’Œæ ‡ç‚¹æ¢å¤ï¼ˆç²¾å¤„ç†ï¼‰
        """
        audio_buffer = []
        buffer_duration = 0
        silence_duration = 0
        
        # å¯è°ƒå‚æ•°
        min_duration = 2.0       # æœ€å°2ç§’å†å‘é€ç»™ASR
        silence_threshold = 1.0  # é™éŸ³1ç§’è§¦å‘
        energy_threshold = 0.01  # è¯­éŸ³èƒ½é‡é˜ˆå€¼ï¼ˆå¯æ ¹æ®ç¯å¢ƒè°ƒæ•´ï¼‰
        
        # å¦‚æœæƒ³å®Œå…¨ä¾èµ–FunASRçš„VADï¼Œå¯ä»¥è®¾ç½®ï¼š
        # energy_threshold = 0.0  # ç¦ç”¨èƒ½é‡æ£€æµ‹
        # silence_threshold = 0.0  # ç¦ç”¨é™éŸ³æ£€æµ‹
        # è¿™æ ·å°±åªæŒ‰ min_duration å®šæ—¶å‘é€
        
        while not self.stop_processing:
            # è·å–éŸ³é¢‘å—
            audio_chunk = self.recorder.get_audio_chunk(timeout=0.5)
            
            if audio_chunk is None:
                continue
            
            # æ·»åŠ åˆ°ç¼“å†²åŒº
            audio_buffer.append(audio_chunk)
            chunk_duration = len(audio_chunk) / self.config.sample_rate
            buffer_duration += chunk_duration
            
            # ç®€å•çš„èƒ½é‡æ£€æµ‹ï¼ˆç¬¬ä¸€å±‚è¿‡æ»¤ï¼‰
            if energy_threshold > 0:
                energy = np.sqrt(np.mean(audio_chunk ** 2))
                is_speech = energy > energy_threshold
                
                if not is_speech:
                    silence_duration += chunk_duration
                else:
                    silence_duration = 0
            else:
                # ç¦ç”¨èƒ½é‡æ£€æµ‹æ—¶ï¼Œè®¤ä¸ºä¸€ç›´æœ‰è¯­éŸ³
                silence_duration = 0
            
            # å†³å®šæ˜¯å¦å‘é€ç»™ASRå¤„ç†
            # ç­–ç•¥ï¼šè¾¾åˆ°æœ€å°æ—¶é•¿ ä¸” æ£€æµ‹åˆ°é™éŸ³ï¼ˆæˆ–ç¦ç”¨äº†é™éŸ³æ£€æµ‹ï¼‰
            should_process = (buffer_duration >= min_duration and 
                            (silence_threshold == 0 or silence_duration >= silence_threshold))
            
            # å½“æ»¡è¶³æ¡ä»¶æ—¶ï¼Œå‘é€ç»™ASRï¼ˆFunASRä¼šè‡ªåŠ¨ç”¨VADåˆ†æ®µå’Œæ·»åŠ æ ‡ç‚¹ï¼‰
            if should_process and audio_buffer:
                log.info(f"å‘é€ {buffer_duration:.2f}s éŸ³é¢‘ç»™ASRå¤„ç†ï¼ˆé™éŸ³: {silence_duration:.2f}sï¼‰")
                
                # åˆå¹¶éŸ³é¢‘
                audio_data = np.concatenate(audio_buffer, axis=0)
                
                # ASRè½¬å†™ - FunASRä¼šè‡ªåŠ¨ä½¿ç”¨VADåˆ†æ®µå’Œæ ‡ç‚¹æ¢å¤
                result = self.asr_engine.transcribe(audio_data, self.config.sample_rate)
                
                if result['success'] and result['text']:
                    text = result['text']
                    timestamp = datetime.now().isoformat()
                    
                    # æ›´æ–°è½¬å†™æ–‡æœ¬
                    self.transcription_text += f"[{timestamp}] {text}\n\n"
                    
                    # å¦‚æœæœ‰åˆ†æ®µä¿¡æ¯ï¼Œä¹Ÿå¯ä»¥æ˜¾ç¤º
                    if 'segments' in result and result['segments']:
                        log.info(f"FunASRè¿”å›äº† {len(result['segments'])} ä¸ªåˆ†æ®µ")
                    
                    # æ–‡æœ¬åˆ†å—
                    chunks = self.text_processor.chunk_text(text, timestamp)
                    
                    # æ·»åŠ åˆ°å‘é‡åº“
                    if chunks:
                        texts = [chunk['text'] for chunk in chunks]
                        metadatas = [{'timestamp': chunk['timestamp']} for chunk in chunks]
                        self.vector_store.add_texts(texts, metadatas)
                        
                        log.info(f"å·²æ·»åŠ  {len(chunks)} ä¸ªæ–‡æœ¬å—åˆ°å‘é‡åº“")
                
                # æ¸…ç©ºç¼“å†²åŒº
                audio_buffer = []
                buffer_duration = 0
                silence_duration = 0
    
    def chat(self, message, history, api_key, base_url, model_name):
        """èŠå¤©åŠŸèƒ½"""
        if not message:
            return history, ""
        
        # åˆå§‹åŒ–RAGå¼•æ“ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self.rag_engine is None or api_key:
            try:
                self.rag_engine = RAGEngine(
                    vector_store=self.vector_store,
                    api_key=api_key or self.config.openai_api_key,
                    base_url=base_url or self.config.openai_base_url,
                    model_name=model_name or self.config.model_name
                )
            except Exception as e:
                history.append((message, f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}"))
                return history, ""
        
        # æŸ¥è¯¢
        result = self.rag_engine.query(
            message,
            top_k=self.config.top_k,
            temperature=self.config.temperature,
            max_tokens=self.config.max_tokens
        )
        
        if result['success']:
            answer = result['answer']
        else:
            answer = result['answer']
        
        history.append((message, answer))
        
        return history, ""
    
    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        doc_count = self.vector_store.get_count()
        status = "ğŸ™ï¸ å½•éŸ³ä¸­..." if self.is_recording else "â¹ï¸ æœªå½•éŸ³"
        
        return f"{status} | å·²å­˜å‚¨æ–‡æœ¬ç‰‡æ®µ: {doc_count}"
    
    def clear_database(self):
        """æ¸…ç©ºæ•°æ®åº“"""
        try:
            self.vector_store.clear()
            self.transcription_text = ""
            return "âœ… å‘é‡åº“å·²æ¸…ç©º", ""
        except Exception as e:
            return f"âŒ æ¸…ç©ºå¤±è´¥: {str(e)}", self.transcription_text

def create_app():
    """åˆ›å»ºGradioåº”ç”¨"""
    app = SoundMemApp()
    
    with gr.Blocks(title="SoundMem - æ™ºèƒ½å½•éŸ³è®°å¿†åŠ©æ‰‹", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸ™ï¸ SoundMem - æ™ºèƒ½å½•éŸ³è®°å¿†åŠ©æ‰‹
        
        å®æ—¶å½•éŸ³è½¬å†™ + æ™ºèƒ½é—®ç­”ï¼Œè®©ä½ çš„å½•éŸ³å†…å®¹å¯ä»¥è¢«æ£€ç´¢å’Œå¯¹è¯
        """)
        
        # åˆå§‹åŒ–æŒ‰é’®
        with gr.Row():
            init_btn = gr.Button("ğŸš€ åˆå§‹åŒ–æ¨¡å‹ï¼ˆé¦–æ¬¡ä½¿ç”¨è¯·ç‚¹å‡»ï¼‰", variant="primary", size="lg")
        
        init_status = gr.Textbox(label="åˆå§‹åŒ–çŠ¶æ€", interactive=False)
        init_btn.click(app.initialize_models, outputs=init_status)
        
        with gr.Row():
            # å·¦ä¾§ï¼šå½•éŸ³æ§åˆ¶
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“ å½•éŸ³æ§åˆ¶")
                
                with gr.Row():
                    start_btn = gr.Button("ğŸ™ï¸ å¼€å§‹å½•éŸ³", variant="primary")
                    stop_btn = gr.Button("â¹ï¸ åœæ­¢å½•éŸ³", variant="stop")
                
                status_text = gr.Textbox(label="å½•éŸ³çŠ¶æ€", interactive=False)
                
                transcription = gr.Textbox(
                    label="å®æ—¶è½¬å†™æ–‡æœ¬",
                    lines=15,
                    interactive=False,
                    placeholder="è½¬å†™çš„æ–‡æœ¬å°†åœ¨è¿™é‡Œæ˜¾ç¤º..."
                )
                
                with gr.Row():
                    stats_text = gr.Textbox(label="ç»Ÿè®¡ä¿¡æ¯", interactive=False)
                    refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°")
                
                clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå‘é‡åº“", variant="stop")
            
            # å³ä¾§ï¼šå¯¹è¯åŒº
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ’¬ æ™ºèƒ½é—®ç­”")
                
                # APIé…ç½®ï¼ˆå¯æŠ˜å ï¼‰
                with gr.Accordion("âš™ï¸ APIé…ç½®", open=False):
                    api_key_input = gr.Textbox(
                        label="API Key",
                        type="password",
                        placeholder="ç•™ç©ºåˆ™ä½¿ç”¨.envä¸­çš„é…ç½®"
                    )
                    base_url_input = gr.Textbox(
                        label="Base URL",
                        placeholder="ç•™ç©ºåˆ™ä½¿ç”¨.envä¸­çš„é…ç½®"
                    )
                    model_input = gr.Textbox(
                        label="æ¨¡å‹åç§°",
                        placeholder="ç•™ç©ºåˆ™ä½¿ç”¨.envä¸­çš„é…ç½®"
                    )
                
                chatbot = gr.Chatbot(
                    label="å¯¹è¯å†å²",
                    height=400
                )
                
                with gr.Row():
                    msg_input = gr.Textbox(
                        label="è¾“å…¥é—®é¢˜",
                        placeholder="é—®æˆ‘å…³äºå½•éŸ³å†…å®¹çš„é—®é¢˜...",
                        scale=4
                    )
                    send_btn = gr.Button("å‘é€", variant="primary", scale=1)
        
        # äº‹ä»¶ç»‘å®š
        start_btn.click(
            app.start_recording,
            outputs=[status_text, transcription]
        )
        
        stop_btn.click(
            app.stop_recording,
            outputs=[status_text, transcription]
        )
        
        refresh_btn.click(
            app.get_stats,
            outputs=stats_text
        )
        
        clear_btn.click(
            app.clear_database,
            outputs=[status_text, transcription]
        )
        
        send_btn.click(
            app.chat,
            inputs=[msg_input, chatbot, api_key_input, base_url_input, model_input],
            outputs=[chatbot, msg_input]
        )
        
        msg_input.submit(
            app.chat,
            inputs=[msg_input, chatbot, api_key_input, base_url_input, model_input],
            outputs=[chatbot, msg_input]
        )
        
        # å®šæ—¶åˆ·æ–°è½¬å†™æ–‡æœ¬å’Œç»Ÿè®¡ä¿¡æ¯
        demo.load(app.get_stats, outputs=stats_text, every=2)
    
    return demo

